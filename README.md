# Detec√ß√£o de Intrus√£o em Redes com Machine Learning

[![Status do Projeto](https://img.shields.io/badge/status-em%20andamento-yellow)](https://github.com/SEU_USUARIO/SEU_REPOSITORIO)

---

## üìñ √çndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Datasets Analisados](#datasets-analisados)
- [NSL-KDD](#nsl-kdd)
- [UNSW-NB15](#unsw-nb15)
- [CIC-IDS-2017](#cic-ids-2017)

---

## üöÄ Sobre o Projeto

Atrav√©s de datasets que re√∫nem dados variados de tr√°fego normal e anormal, podemos tanto aprender padr√µes de ataques cibern√©ticos, como usar o Machine Learning para treinar a IA para identific√°-los. Isso pode se mostrar especialmente √∫til em plataformas **SIEM** (Security Information and Event Management), que normalmente utilizam de regras de correla√ß√£o fixas (ex.: `SE flag == 'S0' E serror_rate > 0.9 ENT√ÉO DoS`), mas com sua moderniza√ß√£o, podem ser integradas a esses modelos de IA treinados que podem identificar at√© mesmo ataques mais sutis e amea√ßas novas (zero-day).

Este projeto tem o objetivo de utilizar t√©cnicas de Machine Learning para o treino desses modelos e tamb√©m entender mais sobre esses ataques, em um estudo misto de Ci√™ncia de Dados/IA e Ciberseguran√ßa/Redes. √â um estudo n√£o necessariamente focado em encontrar a melhor solu√ß√£o para cada caso, mas em explorar solu√ß√µes e t√©cnicas, entender o comportamento das anomalias por meio de an√°lises estat√≠sticas e construir uma boa base nesses temas fazendo estudos complementares que venham a ser √∫teis para a verdadeira compreens√£o do caso.

As an√°lises s√£o feitas originalmente no Google Colab e est√£o com uma c√≥pia neste reposit√≥rio (o link para o Colab est√° no in√≠cio da c√≥pia). N√£o h√° s√≥ c√≥digo, mas explica√ß√£o do c√≥digo e dos conceitos utilizados neste. Para cada um, existe uma vers√£o em ingl√™s e uma em portugu√™s.

---

## üìä Datasets Analisados

Os datasets utilizados nesse projeto s√£o:

### 1. NSL-KDD
* **Status:** Finalizado
* **Descri√ß√£o:** Uma vers√£o de 2009 aprimorada do cl√°ssico KDD'99 (1998/1999). √â not√≥rio por seu desbalanceamento de classes e pelo **"Concept Drift"** (diferen√ßas estat√≠sticas significativas) entre os conjuntos de treino e teste.

### 2. UNSW-NB15
* **Status:** Em andamento
* **Descri√ß√£o:** --

### 3. CIC-IDS-2017
* **Status:** A iniciar
* **Descri√ß√£o:** --

---

## 1Ô∏è‚É£ NSL-KDD

* **Pr√©-processamento:** One-Hot Encoding para categ√≥ricas (`protocol_type`, `service`, `flag`) + Padroniza√ß√£o (`StandardScaler`) "Linha de Base Pura" (treinada apenas no tr√°fego 'normal').
* **Metodologia Principal:** Engenharia de features para a cria√ß√£o de 4 "Risk Scores" (`dos`, `probe`, `r2l`, `u2r`) baseados na soma ponderada dos Z-Scores das **Top 7 features** mais relevantes do heatmap.
* **Modelo:** LightGBM (LGBM) com `is_unbalance=True`, treinado no dataset completo (122 features + 4 "Risk Scores").

**Resultados (Conjunto de Teste):**

| Classe | Precision | Recall | F1-Score | Support |
| :--- | :---: | :---: | :---: | :---: |
| **dos** | 0.99 | 0.99 | 0.99 | 8271 |
| **normal** | 0.99 | 0.99 | 0.99 | 12042 |
| **probe** | 0.98 | 0.99 | 0.99 | 2037 |
| **r2l** | 0.95 | 0.91 | 0.93 | 183 |
| **u2r** | 0.39 | 0.64 | 0.48 | 11 |
| | | | | |
| **accuracy** | | | **0.99** | **22544** |
| **macro avg** | 0.86 | 0.90 | 0.88 | 22544 |
| **weighted avg** | 0.99 | 0.99 | 0.99 | 22544 |

![NSL Confusion Matrix](img/confusion_matrix_nsl-kdd.png)

**Conclus√µes:**

O desafio central do NSL-KDD √© o desbalanceamento extremo e o "Concept Drift" (o conjunto de teste cont√©m 17 ataques que n√£o existem no treino). Uma abordagem de baseline falha completamente (F1-Macro < 0.50).

A metodologia de "Risk Score" se provou **altamente eficaz**. A an√°lise de import√¢ncia das features mostrou que as "Risk Scores" que criamos (especialmente `u2r_risk_score` e `r2l_risk_score`) estavam entre as features mais importantes para o modelo LGBM.

O resultado final (F1-Macro de 0.88) √© excelente, com performance quase perfeita nas classes de alto volume e uma melhoria dr√°stica nas classes raras. O modelo identificou 64% dos ataques `u2r` (contra ~2% do baseline) e 91% dos `r2l`, com uma precis√£o muito alta (95%).

---

## 2Ô∏è‚É£ UNSW-NB15

* **Pr√©-processamento:** --
* **Metodologia Principal:** --
* **Modelo:** --

**Resultados (Conjunto de Teste):**

--

**Conclus√µes:**

--

---

## 3Ô∏è‚É£ CIC-IDS-2017

* **Pr√©-processamento:** --
* **Metodologia Principal:** --
* **Modelo:** --

**Resultados (Conjunto de Teste):**

--

**Conclus√µes:**

--

---
